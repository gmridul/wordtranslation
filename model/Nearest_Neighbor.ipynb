{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Nearest_Neighbor(object):\n",
    "    word_embedding_dict = dict()\n",
    "    word_embedding_nn = dict()\n",
    "    def __init__(self, embeddings_dir, domain_dir, lang_list, k_neighbors, flag='train'):\n",
    "        for lang  in lang_list:\n",
    "            file_path = embeddings_dir+'/wiki.'+lang + '.vec'\n",
    "            #cur_word_embeddings = self.load_word_embeddings(file_path)\n",
    "            #print (np.shape(cur_word_embeddings))\n",
    "            Nearest_Neighbor.word_embedding_dict[lang] = self.load_word_embeddings(file_path, domain_dir, lang, flag)\n",
    "            Nearest_Neighbor.word_embedding_nn[lang] = NearestNeighbors(\\\n",
    "                            n_neighbors=k_neighbors, algorithm='ball_tree', metric='euclidean').fit(Nearest_Neighbor.word_embedding_dict[lang])\n",
    "\n",
    "    def load_word_embeddings(self, file_path, domain_dir, lang, flag):\n",
    "        res = []\n",
    "        words_in_domain = {}\n",
    "        glob_dir = \"\"\n",
    "        \n",
    "        if(flag == 'test'):\n",
    "            glob_dir = domain_dir+ '*' + lang + '*.txt'\n",
    "        else: #train\n",
    "            glob_dir = domain_dir+ '*' + lang + '*train.txt'\n",
    "        \n",
    "        for file in glob.glob(glob_dir):\n",
    "            file_name = (os.path.basename(file))\n",
    "            lang_pair = file_name.split('_')[1].split('.')[0].split('-')\n",
    "            index= -1\n",
    "            if lang == lang_pair[0]: \n",
    "                index = 0\n",
    "            elif lang == lang_pair[1]:\n",
    "                index = 1\n",
    "            with open(file, 'r') as f:\n",
    "                for line in f:\n",
    "                    word = line.split(' ')[index].strip()\n",
    "                    words_in_domain[word] = True\n",
    "        \n",
    "        with open(file_path, encoding='utf-8') as f:\n",
    "            next(f)\n",
    "            for line in f:\n",
    "                vec = line.split(' ')\n",
    "                if vec[0].strip() in words_in_domain:\n",
    "                    #print(vec[0].strip())\n",
    "                    res.append([float(x) for x in vec[1:-1]])\n",
    "        return np.array(res)\n",
    "        \n",
    "    # word_vec is 2D vector list of words.\n",
    "    def knn(self, word_vec, lang, k=10):\n",
    "        #assert input word_vec is 2D \n",
    "        #assert language is one of the keys\n",
    "        #assert k < 10 \n",
    "        dist, index = Nearest_Neighbor.word_embedding_nn[lang].kneighbors(word_vec)\n",
    "        return Nearest_Neighbor.word_embedding_dict[lang][index[:, 0:k]]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "### Usage\n",
    "n = Nearest_Neighbor (embeddings_dir=\"D:/UCSD/F17/CSE293/\", domain_dir='D:/UCSD/F17/CSE293/wordtranslation/model/data/', lang_list=['pt', 'en'], k_neighbors=10)\n",
    "point = Nearest_Neighbor.word_embedding_dict['pt'][0:10]\n",
    "np.shape(n.knn(point, \"pt\", 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nearest_ne = Nearest_Neighbor(embeddings_dir=\"D:/UCSD/F17/CSE293/\", domain_dir='D:/UCSD/F17/CSE293/wordtranslation/model/data/', lang_list=['dummy'], k_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.,  2.,  3.],\n",
       "        [ 2.,  3.,  4.]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nearest_ne.knn([[1, 2, 3]], \"dummy\", 2)\n",
    "#Nearest_Neighbor.word_embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
